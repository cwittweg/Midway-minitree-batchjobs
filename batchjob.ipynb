{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### run imports, configure pax and hax\n",
    "%run \"Initialize.ipynb\"\n",
    "from pax import units, configuration, datastructure\n",
    "pax_config = configuration.load_configuration('XENON1T')\n",
    "n_channels = pax_config['DEFAULT']['n_channels']\n",
    "pmts = pax_config['DEFAULT']['pmts']\n",
    "tpc_height = pax_config['DEFAULT']['tpc_length']\n",
    "tpc_radius = pax_config['DEFAULT']['tpc_radius']\n",
    "gains = pax_config['DEFAULT']['gains']\n",
    "# get channel number of busy on\n",
    "busy_on_ch = pax_config['DEFAULT']['channels_in_detector']['busy_on'][0]\n",
    "\n",
    "import hax\n",
    "from hax import cuts\n",
    "\n",
    "hax.__version__\n",
    "hax.init(experiment='XENON1T',\n",
    "         raw_data_access_mode='local',\n",
    "         raw_data_local_path='/project/lgrandi/xenon1t/raw',\n",
    "        main_data_paths=['/project/lgrandi/xenon1t/processed/pax_v6.6.5' , \n",
    "                         '/project2/lgrandi/xenon1t/processed/pax_v6.6.5'], # add here correct path for AmBe\n",
    "        #minitree_paths = ['/project*/lgrandi/xenon1t/minitrees', \n",
    "         #                 '/project*/lgrandi/xenon1t/minitrees/latest',\n",
    "          #               '.', '/project*/lgrandi/xenon1t/minitrees/pax_v6.6.5'],\n",
    "        #minitree_paths = ['/home/fieguth/DEC','*'],\n",
    "         pax_version_policy= '6.6.5'  )\n",
    "        #minitree_paths = ['/project*/lgrandi/xenon1t/minitrees/latest'],\n",
    "         #pax_version_policy= '6.6.5'  )\n",
    "\n",
    "\n",
    "\n",
    "datasets = hax.runs.datasets # this variable holds all dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "## Select datasets\n",
    "#dsets = datasets[(datasets.source__type == 'none')| (datasets.source__type == 'None')]\n",
    "dsets = hax.runs.tags_selection(include=['sciencerun1'], exclude=['bad', 'messy', '*trip', '*quake','test'])\n",
    "dsets = dsets[(dsets.source__type == 'none')| (dsets.source__type == 'None')] # \n",
    "dsets = dsets[(dsets.location != '')]\n",
    "#dsets['run_time_s'] = pd.to_timedelta(pd.to_datetime(dsets.end) - pd.to_datetime(dsets.start)).dt.seconds\n",
    "#dsets = dsets[dsets.run_time_s > 3600] # select only runs of an hour or more, CHECK IF NECESSARY FOR AMBE\n",
    "# some of the datasets had anomalously high background rates. I didn't use these datasets for the analysis.\n",
    "# dsets['background_rate'] = dsets.trigger__events_built/dsets.run_time_s # background rate (avg. events/s)\n",
    "\n",
    "# select data range\n",
    "dsets = dsets[(dsets.start > pd.to_datetime('06/06/2017')) & (dsets.end < pd.to_datetime('06/13/2017'))]\n",
    "#dsets = dsets[(dsets.start > pd.to_datetime('1/10/2017')) & (dsets.end < pd.to_datetime('1/18/2017'))]\n",
    "dsets['start_date'] = dsets.start.dt.date\n",
    "\n",
    "run_names = dsets.name\n",
    "\n",
    "# get rid of problematic runs\n",
    "bad_runs = ['161204_1517','170111_031','170111_0314'] # n'o minitree'\n",
    "\n",
    "for run in bad_runs:\n",
    "    run_names = run_names[run_names != run]\n",
    "    dsets  = dsets[dsets.name != run]\n",
    "\n",
    "# In order to create the batch jobs we don't need the run number (=index) instead of the time and date\n",
    "run_numbers = dsets.index\n",
    "print(len(run_numbers.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:b'Submitted batch job 29617861\\n'\n",
      "INFO:root:b'Submitted batch job 29617862\\n'\n",
      "INFO:root:b'Submitted batch job 29617864\\n'\n",
      "INFO:root:b'Submitted batch job 29617866\\n'\n",
      "INFO:root:b'Submitted batch job 29617869\\n'\n",
      "INFO:root:b'Submitted batch job 29617870\\n'\n",
      "INFO:root:b'Submitted batch job 29617871\\n'\n",
      "INFO:root:b'Submitted batch job 29617872\\n'\n",
      "INFO:root:b'Submitted batch job 29617873\\n'\n",
      "INFO:root:b'Submitted batch job 29617874\\n'\n",
      "INFO:root:b'Submitted batch job 29617875\\n'\n",
      "INFO:root:b'Submitted batch job 29617878\\n'\n",
      "INFO:root:b'Submitted batch job 29617879\\n'\n",
      "INFO:root:b'Submitted batch job 29617880\\n'\n",
      "INFO:root:b'Submitted batch job 29617882\\n'\n",
      "INFO:root:b'Submitted batch job 29617883\\n'\n",
      "INFO:root:b'Submitted batch job 29617884\\n'\n",
      "INFO:root:b'Submitted batch job 29617885\\n'\n",
      "INFO:root:b'Submitted batch job 29617888\\n'\n",
      "INFO:root:b'Submitted batch job 29617889\\n'\n",
      "INFO:root:b'Submitted batch job 29617890\\n'\n",
      "INFO:root:b'Submitted batch job 29617891\\n'\n",
      "INFO:root:b'Submitted batch job 29617892\\n'\n",
      "INFO:root:b'Submitted batch job 29617893\\n'\n",
      "INFO:root:b'Submitted batch job 29617894\\n'\n",
      "INFO:root:b'Submitted batch job 29617895\\n'\n",
      "INFO:root:b'Submitted batch job 29617896\\n'\n",
      "INFO:root:b'Submitted batch job 29617899\\n'\n",
      "INFO:root:b'Submitted batch job 29617900\\n'\n",
      "INFO:root:b'Submitted batch job 29617901\\n'\n",
      "INFO:root:b'Submitted batch job 29617902\\n'\n",
      "INFO:root:b'Submitted batch job 29617903\\n'\n",
      "INFO:root:b'Submitted batch job 29617904\\n'\n",
      "INFO:root:b'Submitted batch job 29617905\\n'\n",
      "INFO:root:b'Submitted batch job 29617906\\n'\n",
      "INFO:root:b'Submitted batch job 29617907\\n'\n",
      "INFO:root:b'Submitted batch job 29617908\\n'\n",
      "INFO:root:b'Submitted batch job 29617909\\n'\n",
      "INFO:root:b'Submitted batch job 29617910\\n'\n",
      "INFO:root:b'Submitted batch job 29617913\\n'\n",
      "INFO:root:b'Submitted batch job 29617914\\n'\n",
      "INFO:root:b'Submitted batch job 29617915\\n'\n",
      "INFO:root:b'Submitted batch job 29617916\\n'\n",
      "INFO:root:b'Submitted batch job 29617917\\n'\n",
      "INFO:root:b'Submitted batch job 29617918\\n'\n",
      "INFO:root:b'Submitted batch job 29617919\\n'\n",
      "INFO:root:b'Submitted batch job 29617922\\n'\n",
      "INFO:root:b'Submitted batch job 29617924\\n'\n",
      "INFO:root:b'Submitted batch job 29617925\\n'\n"
     ]
    }
   ],
   "source": [
    "# The link to the original batch queue examples can be found here: https://github.com/XENON1T/XeAnalysisScripts/tree/master/examples/BatchMinitrees_Ted\n",
    "\n",
    "# 2016-09, sanderb@nikhef.nl: from Chris with Sander's personalization\n",
    "\n",
    "# log files will be created in the folder where you run this script\n",
    "# For every job you will get an email, make sure this won't be blocked as it will look like spam if you get 500+ emails\n",
    "# You need write permission for making the processing_dir folder\n",
    "\n",
    "x = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name={run}\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem-per-cpu=2000\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH --output=minitree_%J.log\n",
    "#SBATCH --error=minitree_%J.log\n",
    "#SBATCH --account=pi-lgrandi\n",
    "#SBATCH --qos=xenon1t\n",
    "#SBATCH --partition=xenon1t\n",
    "#SBATCH --mail-user=<c.wittweg@wwu.de>\n",
    "export PATH=/project/lgrandi/anaconda3/bin:$PATH\n",
    "export PROCESSING_DIR=/home/wittweg/minitrees/minitree_{run}\n",
    "        \n",
    "mkdir -p ${{PROCESSING_DIR}}\n",
    "cd ${{PROCESSING_DIR}}\n",
    "rm -f pax_event_class*\n",
    "source activate pax_head\n",
    "\n",
    "echo python ..treebuilder.py {run}\n",
    "python ../treebuilder.py {run}\n",
    "\n",
    "mv *root /home/wittweg/minitrees/\n",
    "\"\"\"\n",
    "\n",
    "# Use submit procedure from CAX\n",
    "from cax.qsub import submit_job\n",
    "\n",
    "#Define which runs we want to process (max per submit is 500 jobs!)\n",
    "\n",
    "#runs=[10181,10182]\n",
    "\n",
    "# Make sure you do not submit too many jobs\n",
    "if len(run_numbers.values) < 450:\n",
    "    runs = run_numbers.values\n",
    "    # For every run, make and submit the script\n",
    "    for run in runs:\n",
    "        y = x.format(run=run)    \n",
    "        submit_job(y)\n",
    "else:\n",
    "    print('Too many files. Try again')\n",
    "\n",
    "# Check your jobs with: 'qstat -u <username>'\n",
    "# Check number of submitted jobs with 'qstat -u <username> | wc -l' (is off by +2 btw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
